{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of this file is simply to get tweets and store them to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_Key = os.environ.get(\"API_KEY\")\n",
    "API_Key_Secret = os.environ.get(\"API_KEY_SECRET\")\n",
    "Bearer_Token = os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "bearer = 'bearer ' + Bearer_Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://api.twitter.com/2/tweets/search/recent/?query='\n",
    "query_arg_prefix = '-is:retweet  has:links from:'\n",
    "#fixed_args = '-is:retweet  has:links '\n",
    "query_arg_prefix = urllib.parse.quote(query_arg_prefix)\n",
    "\n",
    "user = ''\n",
    "query_arg_suffix = '&max_results=100&tweet.fields=attachments,author_id,context_annotations,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,source,text,withheld&expansions=referenced_tweets.id,geo.place_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runDate = datetime.today().strftime('%Y-%m-%d')\n",
    "print(runDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "        \n",
    "'PatrickMeier'\n",
    ",'ivangayton'\n",
    ",'HIPNorway'\n",
    ",'UN_Innovation'\n",
    ",'ICRC_Innovation'\n",
    ",'ricap_undp'\n",
    ",'Catalyst_2030'\n",
    ",'solvozplatform'\n",
    ",'CEBaP_evidence'\n",
    ",'feraldata'\n",
    ",'Caterina'\n",
    ",'Farrell_Diana'\n",
    ",'Mgorbis'\n",
    ",'AndreaKerzner'\n",
    ",'alicekorngold'\n",
    ",'susanmcp1'\n",
    ",'nilofer'\n",
    ",'ZainabSalbi'\n",
    ",'wayan_vota'\n",
    ",'WeRobotics'\n",
    ",'MykolaKozyr'\n",
    ",'ECAAS_AGData'\n",
    ",'kobotoolbox'\n",
    ",'IvanaJurko'\n",
    ",'msf'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    fullUrl = api_url + query_arg_prefix + user + query_arg_suffix\n",
    "    folder = 'twitter_data/'\n",
    "    fullFilePath = folder + runDate + '_' + user + '.json'\n",
    "    print(fullUrl)\n",
    "    print(fullFilePath)\n",
    "    \n",
    "    \n",
    "    response = requests.get(fullUrl, headers={\"Authorization\":bearer})\n",
    "                            \n",
    "\n",
    "    parsed = json.loads(response.text)\n",
    "    print(json.dumps(parsed, indent=4, sort_keys=True))\n",
    "    \n",
    "    with open(fullFilePath, 'w') as outfile:\n",
    "        outfile.write(json.dumps(parsed, indent=4, sort_keys=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
